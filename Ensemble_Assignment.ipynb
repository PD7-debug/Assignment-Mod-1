{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PD7-debug/Assignment-Mod-1/blob/main/Ensemble_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2451774",
      "metadata": {
        "id": "e2451774"
      },
      "source": [
        "THEORY QUESTION"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d300f15b",
      "metadata": {
        "id": "d300f15b"
      },
      "source": [
        "## Q1. Can we use Bagging for regression problems?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "724fc9aa",
      "metadata": {
        "id": "724fc9aa"
      },
      "source": [
        "**Answer:** Yes, Bagging can be used for both classification and regression problems. In regression, Bagging helps to reduce variance by averaging predictions from multiple models trained on different subsets of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6936f483",
      "metadata": {
        "id": "6936f483"
      },
      "source": [
        "## Q2. What is the difference between multiple model training and single model training?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f1c10e4",
      "metadata": {
        "id": "1f1c10e4"
      },
      "source": [
        "**Answer:** Single model training involves using one algorithm to make predictions, while multiple model training (ensemble) combines predictions from several models to improve performance and reduce overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ed97179",
      "metadata": {
        "id": "9ed97179"
      },
      "source": [
        "## Q3. Explain the concept of feature randomness in Random Forest."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6321bf7",
      "metadata": {
        "id": "d6321bf7"
      },
      "source": [
        "**Answer:** In Random Forest, feature randomness is introduced by selecting a random subset of features for each split in a tree. This increases diversity among trees and helps reduce overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da638b77",
      "metadata": {
        "id": "da638b77"
      },
      "source": [
        "## Q4. What is OOB (Out-of-Bag) Score?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc2b86f3",
      "metadata": {
        "id": "dc2b86f3"
      },
      "source": [
        "**Answer:** OOB Score is an internal validation method used in Bagging and Random Forest. Each tree is trained on a bootstrap sample, and the samples not included (out-of-bag) are used for validation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88f4ad43",
      "metadata": {
        "id": "88f4ad43"
      },
      "source": [
        "## Q5. How can you measure the importance of features in a Random Forest model?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb675ddb",
      "metadata": {
        "id": "cb675ddb"
      },
      "source": [
        "**Answer:** Random Forest calculates feature importance based on how much each feature reduces the impurity across all trees. This is often computed using Gini importance or Mean Decrease in Impurity."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "493d09c1",
      "metadata": {
        "id": "493d09c1"
      },
      "source": [
        "## Q6. Explain the working principle of a Bagging Classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e92cfe56",
      "metadata": {
        "id": "e92cfe56"
      },
      "source": [
        "**Answer:** A Bagging Classifier builds several models (usually decision trees) on different random subsets of the training data and aggregates their predictions by voting (classification)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0b810f4",
      "metadata": {
        "id": "d0b810f4"
      },
      "source": [
        "## Q7. How do you evaluate a Bagging Classifierâ€™s performance?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1651d7d1",
      "metadata": {
        "id": "1651d7d1"
      },
      "source": [
        "**Answer:** The performance of a Bagging Classifier can be evaluated using accuracy, confusion matrix, precision, recall, F1-score, or cross-validation depending on the dataset and use case."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3ff1cbf",
      "metadata": {
        "id": "f3ff1cbf"
      },
      "source": [
        "## Q8. How does a Bagging Regressor work?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0910df5a",
      "metadata": {
        "id": "0910df5a"
      },
      "source": [
        "**Answer:** A Bagging Regressor works by training multiple regression models on random subsets of the data and averaging their predictions to reduce variance and improve robustness."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9405e3f3",
      "metadata": {
        "id": "9405e3f3"
      },
      "source": [
        "## Q9. What is the main advantage of ensemble techniques?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e6b97a9",
      "metadata": {
        "id": "4e6b97a9"
      },
      "source": [
        "**Answer:** The main advantage of ensemble techniques is improved model performance through reduced variance, bias, or improved predictions compared to single models."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9576718f",
      "metadata": {
        "id": "9576718f"
      },
      "source": [
        "## Q10. What is the main challenge of ensemble methods?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6e56fe4",
      "metadata": {
        "id": "f6e56fe4"
      },
      "source": [
        "**Answer:** The main challenge is increased computational cost and complexity in training, as well as the difficulty in interpreting the final ensemble model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0270fe84",
      "metadata": {
        "id": "0270fe84"
      },
      "source": [
        "## Q11. Explain the key idea behind ensemble techniques."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40269b84",
      "metadata": {
        "id": "40269b84"
      },
      "source": [
        "**Answer:** The key idea is to combine predictions from multiple models to form a stronger overall model. This can be done by voting, averaging, or stacking."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e05444bb",
      "metadata": {
        "id": "e05444bb"
      },
      "source": [
        "## Q12. What is a Random Forest Classifier?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "076ad2a9",
      "metadata": {
        "id": "076ad2a9"
      },
      "source": [
        "**Answer:** A Random Forest Classifier is an ensemble method that builds multiple decision trees and outputs the class that is the mode of predictions from all trees."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc52a626",
      "metadata": {
        "id": "bc52a626"
      },
      "source": [
        "## Q13. What are the main types of ensemble techniques?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3657f07b",
      "metadata": {
        "id": "3657f07b"
      },
      "source": [
        "**Answer:** The main types include Bagging, Boosting, and Stacking. Bagging reduces variance, Boosting reduces bias, and Stacking combines multiple classifiers via a meta-model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b1979de",
      "metadata": {
        "id": "4b1979de"
      },
      "source": [
        "## Q14. What is ensemble learning in machine learning?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41f63ce2",
      "metadata": {
        "id": "41f63ce2"
      },
      "source": [
        "**Answer:** Ensemble learning is a technique where multiple models are trained and combined to solve a particular machine learning problem to improve generalizability and robustness."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e575cecf",
      "metadata": {
        "id": "e575cecf"
      },
      "source": [
        "## Q15. When should we avoid using ensemble methods?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a91a6574",
      "metadata": {
        "id": "a91a6574"
      },
      "source": [
        "**Answer:** Ensemble methods should be avoided when the base model already performs very well or when computational resources are limited."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3239f87",
      "metadata": {
        "id": "e3239f87"
      },
      "source": [
        "## Q16. How does Bagging help in reducing overfitting?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9ed5bc0",
      "metadata": {
        "id": "a9ed5bc0"
      },
      "source": [
        "**Answer:** Bagging reduces overfitting by averaging multiple models trained on different bootstrap samples, reducing the variance of predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31a99592",
      "metadata": {
        "id": "31a99592"
      },
      "source": [
        "## Q17. Why is Random Forest better than a single Decision Tree?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ccf06a9",
      "metadata": {
        "id": "3ccf06a9"
      },
      "source": [
        "**Answer:** Random Forest improves performance over a single Decision Tree by reducing overfitting through averaging and introducing randomness in feature selection."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3dc13e1a",
      "metadata": {
        "id": "3dc13e1a"
      },
      "source": [
        "## Q18. What is the role of bootstrap sampling in Bagging?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb14434d",
      "metadata": {
        "id": "fb14434d"
      },
      "source": [
        "**Answer:** Bootstrap sampling involves randomly selecting samples with replacement to create multiple training datasets. It ensures each model is trained on slightly different data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e40d565d",
      "metadata": {
        "id": "e40d565d"
      },
      "source": [
        "## Q19. What are some real-world applications of ensemble techniques?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1323b9d1",
      "metadata": {
        "id": "1323b9d1"
      },
      "source": [
        "**Answer:** Real-world applications include fraud detection, spam filtering, recommendation systems, credit scoring, and medical diagnosis."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6896fc6a",
      "metadata": {
        "id": "6896fc6a"
      },
      "source": [
        "## Q20. What is the difference between Bagging and Boosting?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a4e438e",
      "metadata": {
        "id": "1a4e438e"
      },
      "source": [
        "**Answer:** Bagging builds models in parallel and combines their outputs, while Boosting builds models sequentially, each trying to correct the errors of its predecessor."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PRACTICAL QUESTION"
      ],
      "metadata": {
        "id": "x5HdezuokOh9"
      },
      "id": "x5HdezuokOh9"
    },
    {
      "cell_type": "markdown",
      "id": "73a37121",
      "metadata": {
        "id": "73a37121"
      },
      "source": [
        "## Q21. Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "226e2ade",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "226e2ade",
        "outputId": "ab19b22f-df12-4894-ae26-d3ad8c868403"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "model = BaggingClassifier(DecisionTreeClassifier(), n_estimators=10)\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, model.predict(X_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0c39335",
      "metadata": {
        "id": "a0c39335"
      },
      "source": [
        "## Q22. Train a Bagging Regressor using Decision Trees and evaluate using Mean Squared Error (MSE)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8543012a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8543012a",
        "outputId": "0f25f010-44ed-49c1-a7de-9ca1574b2aa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.2657709758285341\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X, y = fetch_california_housing(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "model = BaggingRegressor(DecisionTreeRegressor(), n_estimators=10)\n",
        "model.fit(X_train, y_train)\n",
        "print(\"MSE:\", mean_squared_error(y_test, model.predict(X_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "703ad5c1",
      "metadata": {
        "id": "703ad5c1"
      },
      "source": [
        "## Q23. Train a Random Forest Classifier on the Breast Cancer dataset and print feature importance scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "77af09e5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77af09e5",
        "outputId": "b93e17d4-3bdf-45c3-e2df-7fb16c83fbe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importances: [0.03108088 0.01465372 0.0689355  0.02603848 0.006971   0.0173372\n",
            " 0.02315151 0.07231959 0.00426295 0.00302916 0.02533084 0.00448961\n",
            " 0.00466304 0.03123423 0.0050654  0.00310194 0.00566557 0.00432531\n",
            " 0.0034708  0.00610022 0.08691968 0.01769111 0.16926345 0.13463523\n",
            " 0.01264723 0.02300338 0.02256598 0.15462541 0.00896514 0.00845642]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X, y)\n",
        "importances = model.feature_importances_\n",
        "print(\"Feature Importances:\", importances)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2028af1",
      "metadata": {
        "id": "b2028af1"
      },
      "source": [
        "## Q24. Train a Random Forest Regressor and compare its performance with a single Decision Tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0cf1ef84",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cf1ef84",
        "outputId": "c1f9856a-442b-4a03-988a-a85b9c1653d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree R^2: 0.6328795241768423\n",
            "Random Forest R^2: 0.822079323278362\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "dt = DecisionTreeRegressor()\n",
        "rf = RandomForestRegressor()\n",
        "dt.fit(X_train, y_train)\n",
        "rf.fit(X_train, y_train)\n",
        "print(\"Decision Tree R^2:\", dt.score(X_test, y_test))\n",
        "print(\"Random Forest R^2:\", rf.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f487a91a",
      "metadata": {
        "id": "f487a91a"
      },
      "source": [
        "## Q25. Compute the Out-of-Bag (OOB) Score for a Random Forest Classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d821c3c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d821c3c7",
        "outputId": "b4981f85-c561-4c61-d720-ec63fe7c2951"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOB Score: 0.9533333333333334\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Initialize RandomForestClassifier with oob_score=True\n",
        "rf = RandomForestClassifier(oob_score=True, n_estimators=100, random_state=42, bootstrap=True)\n",
        "\n",
        "# Fit model\n",
        "rf.fit(X, y)\n",
        "\n",
        "# Get OOB score\n",
        "oob_score = rf.oob_score_\n",
        "print(\"OOB Score:\", oob_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1997774b",
      "metadata": {
        "id": "1997774b"
      },
      "source": [
        "## Q26. Train a Bagging Classifier using SVM as a base estimator and print accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "606f5708",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "606f5708",
        "outputId": "6c4adfb9-6ef2-40b8-a6b6-4058bb9da881"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize BaggingClassifier with SVM as base estimator\n",
        "bagging_clf = BaggingClassifier(estimator=SVC(), n_estimators=10, random_state=42)\n",
        "\n",
        "# Fit model\n",
        "bagging_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = bagging_clf.predict(X_test)\n",
        "\n",
        "# Print accuracy\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "724a3071",
      "metadata": {
        "id": "724a3071"
      },
      "source": [
        "## Q27. Train a Random Forest Classifier with different numbers of trees and compare accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "8ca3d02f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ca3d02f",
        "outputId": "dbf2c33c-235d-4dff-c032-5c287393d0e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with 10 trees: 1.0\n",
            "Accuracy with 50 trees: 1.0\n",
            "Accuracy with 100 trees: 1.0\n"
          ]
        }
      ],
      "source": [
        "for n in [10, 50, 100]:\n",
        "    rf = RandomForestClassifier(n_estimators=n)\n",
        "    rf.fit(X_train, y_train)\n",
        "    print(f\"Accuracy with {n} trees:\", rf.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9b4a020",
      "metadata": {
        "id": "a9b4a020"
      },
      "source": [
        "## Q28. Train a Bagging Classifier using Logistic Regression as a base estimator and print AUC score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "215aca73",
      "metadata": {
        "id": "215aca73"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "28d4ff38",
      "metadata": {
        "id": "28d4ff38"
      },
      "source": [
        "## Q29. Train a Random Forest Regressor and analyze feature importance scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "80c2ec81",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80c2ec81",
        "outputId": "9bb8d239-4af4-4628-fd2e-e09349f929e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature importances: [0.00784048 0.00945195 0.43071171 0.55199586]\n"
          ]
        }
      ],
      "source": [
        "model = RandomForestRegressor()\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Feature importances:\", model.feature_importances_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "072e39ed",
      "metadata": {
        "id": "072e39ed"
      },
      "source": [
        "## Q30. Train an ensemble model using both Bagging and Random Forest and compare accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "cc56468e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc56468e",
        "outputId": "208086ea-3e21-45ba-892b-4f83827fffca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Accuracy: 1.0\n",
            "Random Forest Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "bag = BaggingClassifier(DecisionTreeClassifier(), n_estimators=10)\n",
        "rf = RandomForestClassifier(n_estimators=10)\n",
        "bag.fit(X_train, y_train)\n",
        "rf.fit(X_train, y_train)\n",
        "print(\"Bagging Accuracy:\", bag.score(X_test, y_test))\n",
        "print(\"Random Forest Accuracy:\", rf.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5451ce6",
      "metadata": {
        "id": "b5451ce6"
      },
      "source": [
        "## Q31. Train a Random Forest Classifier and tune hyperparameters using GridSearchCV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "4e8f965c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e8f965c",
        "outputId": "88e714b4-b126-4ed3-b347-5f149326647a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'max_depth': 3, 'n_estimators': 10}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params = {'n_estimators': [10, 50], 'max_depth': [3, 5, None]}\n",
        "grid = GridSearchCV(RandomForestClassifier(), param_grid=params, cv=3)\n",
        "grid.fit(X_train, y_train)\n",
        "print(\"Best params:\", grid.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97c8fd96",
      "metadata": {
        "id": "97c8fd96"
      },
      "source": [
        "## Q32. Train a Bagging Regressor with different numbers of base estimators and compare performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "705bc0b7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "705bc0b7",
        "outputId": "22f1aba4-2325-48ca-a124-6500c597143c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score with 5 estimators: 0.9923076923076923\n",
            "Score with 10 estimators: 0.9974358974358974\n",
            "Score with 50 estimators: 0.9979230769230769\n"
          ]
        }
      ],
      "source": [
        "for n in [5, 10, 50]:\n",
        "    model = BaggingRegressor(n_estimators=n)\n",
        "    model.fit(X_train, y_train)\n",
        "    print(f\"Score with {n} estimators:\", model.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9885f1a",
      "metadata": {
        "id": "f9885f1a"
      },
      "source": [
        "## Q33. Train a Random Forest Classifier and analyze misclassified samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "825852eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "825852eb",
        "outputId": "f937c463-50a7-411a-e2aa-30dd95104938"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Misclassified samples: 0\n"
          ]
        }
      ],
      "source": [
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "misclassified = (y_pred != y_test)\n",
        "print(\"Misclassified samples:\", misclassified.sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "990a9b0b",
      "metadata": {
        "id": "990a9b0b"
      },
      "source": [
        "## Q34. Train a Bagging Classifier and compare its performance with a single Decision Tree Classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "c02ef998",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c02ef998",
        "outputId": "8827182b-32f9-40ec-9118-8b7f402b7b19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Single Tree Accuracy: 1.0\n",
            "Bagging Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "dt = DecisionTreeClassifier()\n",
        "bag = BaggingClassifier(DecisionTreeClassifier(), n_estimators=10)\n",
        "dt.fit(X_train, y_train)\n",
        "bag.fit(X_train, y_train)\n",
        "print(\"Single Tree Accuracy:\", dt.score(X_test, y_test))\n",
        "print(\"Bagging Accuracy:\", bag.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70144eb1",
      "metadata": {
        "id": "70144eb1"
      },
      "source": [
        "## Q35. Train a Random Forest Classifier and visualize the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "b4efa446",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "b4efa446",
        "outputId": "03d2be0c-6e89-4ffa-e7e5-f45f8f13941b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "ConfusionMatrixDisplay.from_estimator(rf, X_test, y_test)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "650a0d60",
      "metadata": {
        "id": "650a0d60"
      },
      "source": [
        "## Q36. Train a Stacking Classifier using Decision Trees, SVM, and Logistic Regression, and compare accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "c947d5e8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c947d5e8",
        "outputId": "467ba4de-93e2-4fdc-d483-2251f9d1db3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "\n",
        "stack = StackingClassifier(estimators=[('dt', DecisionTreeClassifier()),\n",
        "                                       ('svc', SVC(probability=True)),\n",
        "                                       ('lr', LogisticRegression())],\n",
        "                           final_estimator=LogisticRegression())\n",
        "stack.fit(X_train, y_train)\n",
        "print(\"Stacking Accuracy:\", stack.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2c54229",
      "metadata": {
        "id": "f2c54229"
      },
      "source": [
        "## Q37. Train a Random Forest Classifier and print the top 5 most important features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "a8d66952",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8d66952",
        "outputId": "55716383-78c4-4613-91f3-34ee285040c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 features: [2 3 0 1]\n"
          ]
        }
      ],
      "source": [
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "importances = rf.feature_importances_\n",
        "top_idx = importances.argsort()[-5:][::-1]\n",
        "print(\"Top 5 features:\", top_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3593d4e8",
      "metadata": {
        "id": "3593d4e8"
      },
      "source": [
        "## Q38. Train a Bagging Classifier and evaluate performance using Precision, Recall, and F1-score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "37572fc8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37572fc8",
        "outputId": "1089f2d7-13ed-496d-9e65-f3ff918a2717"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "y_pred = bag.predict(X_test)\n",
        "print(\"Precision:\", precision_score(y_test, y_pred, average='macro'))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
        "print(\"F1-score:\", f1_score(y_test, y_pred, average='macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c45653f",
      "metadata": {
        "id": "1c45653f"
      },
      "source": [
        "## Q39. Train a Random Forest Classifier and analyze the effect of max_depth on accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "5dcb82c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dcb82c4",
        "outputId": "a5b37f40-e493-4980-94de-7d036347f752"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Depth 3: Accuracy = 1.0\n",
            "Max Depth 5: Accuracy = 1.0\n",
            "Max Depth 10: Accuracy = 1.0\n"
          ]
        }
      ],
      "source": [
        "for depth in [3, 5, 10]:\n",
        "    rf = RandomForestClassifier(max_depth=depth)\n",
        "    rf.fit(X_train, y_train)\n",
        "    print(f\"Max Depth {depth}: Accuracy = {rf.score(X_test, y_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4de884c3",
      "metadata": {
        "id": "4de884c3"
      },
      "source": [
        "## Q40. Train a Bagging Regressor using different base estimators (DecisionTree and KNeighbors) and compare performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "d4394480",
      "metadata": {
        "id": "d4394480"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "4015908d",
      "metadata": {
        "id": "4015908d"
      },
      "source": [
        "## Q41. Train a Random Forest Classifier and evaluate its performance using ROC-AUC Score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "9af8ef85",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "9af8ef85",
        "outputId": "904ca57d-1b19-4c12-9a16-52f477a1ec4d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "multi_class must be in ('ovo', 'ovr')",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-26-360153087.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ROC AUC:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    632\u001b[0m             )\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multi_class must be in ('ovo', 'ovr')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         return _multiclass_roc_auc_score(\n\u001b[1;32m    636\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: multi_class must be in ('ovo', 'ovr')"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "y_prob = rf.predict_proba(X_test)\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob[:,1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f03e7b7",
      "metadata": {
        "id": "6f03e7b7"
      },
      "source": [
        "## Q42. Train a Bagging Classifier and evaluate its performance using cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "74eacf67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74eacf67",
        "outputId": "4f9504d6-c172-4a6a-db8b-ac04b88bdd2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV Accuracy: 0.9600000000000002\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(BaggingClassifier(), X, y, cv=5)\n",
        "print(\"CV Accuracy:\", scores.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "774d7902",
      "metadata": {
        "id": "774d7902"
      },
      "source": [
        "## Q43. Train a Random Forest Classifier and plot the Precision-Recall curve."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "d55a2ba5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "d55a2ba5",
        "outputId": "2f216be4-172d-4af6-8b6c-a985328cdff4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "multiclass format is not supported",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-28-3735095662.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_recall_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Recall\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mprecision_recall_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate, probas_pred)\u001b[0m\n\u001b[1;32m   1003\u001b[0m         \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobas_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1005\u001b[0;31m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0m\u001b[1;32m   1006\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: multiclass format is not supported"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_scores = rf.predict_proba(X_test)[:,1]\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_scores)\n",
        "plt.plot(recall, precision)\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dee5c542",
      "metadata": {
        "id": "dee5c542"
      },
      "source": [
        "## Q44. Train a Stacking Classifier with Random Forest and Logistic Regression and compare accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "ca7f87b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca7f87b4",
        "outputId": "0b95fc9d-e295-459b-e80a-359d45d27eeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "stack = StackingClassifier(estimators=[('rf', RandomForestClassifier()),\n",
        "                                             ('lr', LogisticRegression())],\n",
        "                                 final_estimator=LogisticRegression())\n",
        "stack.fit(X_train, y_train)\n",
        "print(\"Stacking Accuracy:\", stack.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ef3c3d1",
      "metadata": {
        "id": "1ef3c3d1"
      },
      "source": [
        "## Q45. Train a Bagging Regressor with different levels of bootstrap samples and compare performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "6016b80b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6016b80b",
        "outputId": "4b100a41-88a9-4a7c-d482-a39a547299c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrap=True: Score = 0.9990384615384615\n",
            "Bootstrap=False: Score = 1.0\n"
          ]
        }
      ],
      "source": [
        "for b in [True, False]:\n",
        "    model = BaggingRegressor(bootstrap=b)\n",
        "    model.fit(X_train, y_train)\n",
        "    print(f\"Bootstrap={b}: Score = {model.score(X_test, y_test)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}